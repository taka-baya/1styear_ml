{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.Moduleによるネットワークモデルの定義\n",
    "class Mnist_net(nn.Module):\n",
    "    def __init__(self, INPUT_FEATURES=784, OUTPUT_RESULTS=10):\n",
    "        # 定数（モデル定義時に必要となるもの）\n",
    "        self.INPUT_FEATURES = INPUT_FEATURES# 入力（特徴）の数： 2\n",
    "        self.LAYER1_NEURONS = 256      # ニューロンの数： 256\n",
    "        self.LAYER2_NEURONS = 128      # ニューロンの数： 128\n",
    "        self.OUTPUT_RESULTS = OUTPUT_RESULTS# 出力結果の数： 10\n",
    "\n",
    "        super(Mnist_net, self).__init__()\n",
    "        # 入力層→中間層①：1つ目のレイヤー（layer）\n",
    "        self.layer1 = nn.Linear(\n",
    "            self.INPUT_FEATURES,                # 入力ユニット数：784\n",
    "            self.LAYER1_NEURONS)                # 次のレイヤーの出力ユニット数：256\n",
    "\n",
    "        # 中間層①→中間層②：2つ目のレイヤー（layer）\n",
    "        self.layer2 = nn.Linear(\n",
    "            self.LAYER1_NEURONS,                # 入力ユニット数：256\n",
    "            self.LAYER2_NEURONS)                # 次のレイヤーへの出力ユニット数：128\n",
    "\n",
    "        # 中間層②→出力層：2つ目のレイヤー（layer）\n",
    "        self.layer_out = nn.Linear(\n",
    "            self.LAYER2_NEURONS,                # 入力ユニット数：128\n",
    "            self.OUTPUT_RESULTS)                # 出力結果への出力ユニット数：10\n",
    "\n",
    "    def forward(self, x):\n",
    "        # フィードフォワードを定義\n",
    "        # 「出力＝活性化関数（第n層（入力））」の形式で記述する\n",
    "        x = x.view(-1, 784) # 28×28の配列を784の一次元配列に変換\n",
    "        x = F.relu(self.layer1(x))  # 活性化関数はreluとして定義\n",
    "        x = F.relu(self.layer2(x))  # 同上 \n",
    "        x = F.softmax(self.layer_out(x), dim=1)  # 出力する際はsoftmaxを使用\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get_mnist_data関数\n",
    "> Mnistのデータセットをダウンロードしてくる\n",
    "batch_size          # バッチサイズ\n",
    "\"\"\"\n",
    "def Get_mnist_data(batch_size):\n",
    "    # Totenser関数でtensor化\n",
    "    # Normalise関数で正規化(-1.0〜1.0をとるような値として変換)\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, ), (0.5, ))])\n",
    "    \n",
    "    # 変数datasetにMNISTのデータセットを格納\n",
    "    # ダウンロードしたデータセットは、./dataフォルダに配置される。\n",
    "    train_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform, target_transform=None)\n",
    "    # trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform, target_transform=None)\n",
    "    # testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    return train_dataset, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mnist_net(\n",
       "  (layer1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (layer2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (layer_out): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Mnist_net()\n",
    "model.load_state_dict(torch.load(\"./mnist_model\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128 # バッチサイズ: 128\n",
    "loader_train, loader_valid = Get_mnist_data(batch_size)\n",
    "valid_X = loader_valid[0][0]\n",
    "valid_y = loader_valid[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = model(valid_X) # 出力結果\n",
    "_, pred_y = torch.max(pred_y.data, 1)\n",
    "pred_y = pred_y.numpy()\n",
    "valid_y = valid_y.numpy()\n",
    "\n",
    "print(\"model out : {}\".format(pred_y))\n",
    "print(\"answer : {}\".format(valid_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
