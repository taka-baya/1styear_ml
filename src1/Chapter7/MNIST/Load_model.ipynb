{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリ(パッケージ)のインポート\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成したモデルのネットワークをそのままコピペ\n",
    "# torch.nn.Moduleによるネットワークモデルの定義\n",
    "class Mnist_net(nn.Module):\n",
    "    def __init__(self, INPUT_FEATURES=784, OUTPUT_RESULTS=10):\n",
    "        # 定数（モデル定義時に必要となるもの）\n",
    "        self.INPUT_FEATURES = INPUT_FEATURES# 入力（特徴）の数： 2\n",
    "        self.LAYER1_NEURONS = 256      # ニューロンの数： 256\n",
    "        self.LAYER2_NEURONS = 128      # ニューロンの数： 128\n",
    "        self.OUTPUT_RESULTS = OUTPUT_RESULTS# 出力結果の数： 10\n",
    "\n",
    "        super(Mnist_net, self).__init__()\n",
    "        # 入力層→中間層①：1つ目のレイヤー（layer）\n",
    "        self.layer1 = nn.Linear(\n",
    "            self.INPUT_FEATURES,                # 入力ユニット数：784\n",
    "            self.LAYER1_NEURONS)                # 次のレイヤーの出力ユニット数：256\n",
    "\n",
    "        # 中間層①→中間層②：2つ目のレイヤー（layer）\n",
    "        self.layer2 = nn.Linear(\n",
    "            self.LAYER1_NEURONS,                # 入力ユニット数：256\n",
    "            self.LAYER2_NEURONS)                # 次のレイヤーへの出力ユニット数：128\n",
    "\n",
    "        # 中間層②→出力層：2つ目のレイヤー（layer）\n",
    "        self.layer_out = nn.Linear(\n",
    "            self.LAYER2_NEURONS,                # 入力ユニット数：128\n",
    "            self.OUTPUT_RESULTS)                # 出力結果への出力ユニット数：10\n",
    "\n",
    "    def forward(self, x):\n",
    "        # フィードフォワードを定義\n",
    "        # 「出力＝活性化関数（第n層（入力））」の形式で記述する\n",
    "        x = x.view(-1, 784) # 28×28の配列を784の一次元配列に変換\n",
    "        x = F.relu(self.layer1(x))  # 活性化関数はreluとして定義\n",
    "        x = F.relu(self.layer2(x))  # 同上 \n",
    "        x = F.softmax(self.layer_out(x), dim=1)  # 出力する際はsoftmaxを使用\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Get_mnist_data関数\n",
    "> Mnistのデータセットをダウンロードしてくる\n",
    "batch_size          # バッチサイズ\n",
    "\"\"\"\n",
    "def Get_mnist_data(batch_size):\n",
    "    # Totenser関数でtensor化\n",
    "    # Normalise関数で正規化(-1.0〜1.0をとるような値として変換)\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, ), (0.5, ))])\n",
    "    \n",
    "    # 変数datasetにMNISTのデータセットを格納\n",
    "    # ダウンロードしたデータセットは、./dataフォルダに配置される。\n",
    "    # 訓練用のデータセットを変数train_datasetに格納\n",
    "    train_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform, target_transform=None)\n",
    "    \n",
    "    # 学習する必要がないので、DataLoaderを用いてバッチサイズにまとめる処理は行わない\n",
    "    # trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    \n",
    "    # テスト(検証)用のデータセットを変数test_datasetに格納\n",
    "    test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform, target_transform=None)\n",
    "    \n",
    "    # 学習する必要がないので、DataLoaderを用いてバッチサイズにまとめる処理は行わない\n",
    "    # testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    \n",
    "    # ダウンロードした訓練用データとテスト(検証)用データを保存\n",
    "    return train_dataset, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mnist_net(\n",
       "  (layer1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (layer2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (layer_out): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習モデルを定義\n",
    "model = Mnist_net() # 変数modelにMnist_netクラスのネットワークモデルを定義\n",
    "\n",
    "# 変数modelに保存した学習したモデルのパラメータを読み込み\n",
    "model.load_state_dict(torch.load(\"./mnist_model\")) \n",
    "\n",
    "# 読み込んだモデルを検証モードにする\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 # バッチサイズ: 128\n",
    "\n",
    "# 変数loader_trainとloader_validに学習用データとテスト用データをダウンロード\n",
    "loader_train, loader_valid = Get_mnist_data(batch_size)\n",
    "\n",
    "# 変数valid_Xにテスト用データの一番目の28×28の画像データの値を格納\n",
    "valid_X = loader_valid[0][0]\n",
    "\n",
    "# 変数valid_yにテスト用データの一番目の28×28の画像データの正解ラベルを格納\n",
    "valid_y = loader_valid[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model out : [7]\n",
      "answer : 7\n"
     ]
    }
   ],
   "source": [
    "# 読み込んだモデルに変数valid_Xに格納された28×28の画像データの値を入力し、変数pred_yに出力\n",
    "pred_y = model(valid_X)\n",
    "\n",
    "# 変数pred_yは10個の値(onehotラベル)になっているので、0〜9のどの数字の手書き文字かを表現するラベルに変換する\n",
    "_, pred_y = torch.max(pred_y.data, 1)\n",
    "\n",
    "# 変数pred_yをnumpy型に変換\n",
    "pred_y = pred_y.numpy()\n",
    "\n",
    "# 学習済みのモデルに28×28の画像データを入力して、どの数字の手書き文字かを判別した結果を表示\n",
    "print(\"model out : {}\".format(pred_y))\n",
    "\n",
    "# 実際の正解ラベルを表示\n",
    "print(\"answer : {}\".format(valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
